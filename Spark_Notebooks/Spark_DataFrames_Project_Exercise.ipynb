{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "Spark DataFrames Project Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meryem1425/Spark/blob/master/Spark_DataFrames_Project_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz4hY6_W8mnM"
      },
      "source": [
        "# Spark DataFrames Project Exercise "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2HtTBjf8mna"
      },
      "source": [
        "Let's get some quick practice with your new Spark DataFrame skills, you will be asked some basic questions about some stock market data, in this case Walmart Stock from the years 2012-2017. This exercise will just ask a bunch of questions, unlike the future machine learning exercises, which will be a little looser and be in the form of \"Consulting Projects\", but more on that later!\n",
        "\n",
        "For now, just answer the questions and complete the tasks below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JII31NHB8mnc"
      },
      "source": [
        "#### Use the walmart_stock.csv file to Answer and complete the  tasks below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPcSefXf80PY",
        "outputId": "b7b5962a-1886-49ff-9e71-90813da61741"
      },
      "source": [
        "!pip install spark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spark\n",
            "  Downloading spark-0.2.1.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 30 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 43 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: spark\n",
            "  Building wheel for spark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spark: filename=spark-0.2.1-py3-none-any.whl size=58761 sha256=2759c1d0c7fb34d67f34618f5cbeb301abdf59944abdc51776779b52cb530636\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/0e/f1/164619f9920fb447d294afaae11a7715bd442ded7225953d72\n",
            "Successfully built spark\n",
            "Installing collected packages: spark\n",
            "Successfully installed spark-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P0YuOya86A3",
        "outputId": "793f1c7a-ccf5-4245-fc8f-7a4045516072"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 38 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 43.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=cbbc307eff673959fa6f51bd1782dd7b18697f2cab3c28d9c9958f81ca56c6b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19FK8Rfo850K",
        "outputId": "20f5896c-3b9c-49b6-e43d-8c43c531aed6"
      },
      "source": [
        "!pip install install-jdk"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting install-jdk\n",
            "  Downloading install-jdk-0.3.0.tar.gz (3.8 kB)\n",
            "Building wheels for collected packages: install-jdk\n",
            "  Building wheel for install-jdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for install-jdk: filename=install_jdk-0.3.0-py3-none-any.whl size=3740 sha256=cdb1e43336f1c589349a75729f6be37c76ca3ff518a53bd4ecc4ef9712c74c05\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/91/c1/8f013bf264e0598257fd7c9e602c971ac005df0d40057bf697\n",
            "Successfully built install-jdk\n",
            "Installing collected packages: install-jdk\n",
            "Successfully installed install-jdk-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qqy3M3W8mnd"
      },
      "source": [
        "#### Start a simple Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "M0FB0owo8mne"
      },
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHw_tAxK9dMZ"
      },
      "source": [
        "spark = SparkSession.builder.appName('proje').getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx251rqt8mnf"
      },
      "source": [
        "#### Load the Walmart Stock CSV File, have Spark infer the data types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "X6n0AjWv8mng"
      },
      "source": [
        "df = spark.read.csv('walmart_stock.csv', inferSchema=True, header=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AigQYcN78mnh"
      },
      "source": [
        "#### What are the column names?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ldO7BCk93MS",
        "outputId": "2fa4713c-16f1-4a99-f110-cd8bd6daf316"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMHh4bh58mnp"
      },
      "source": [
        "#### What does the Schema look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJS78dAW8mnq",
        "outputId": "11f0a577-eb70-4c9c-973f-e7712f0c515a"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNT4uPzu8mns"
      },
      "source": [
        "#### Print out the first 5 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARac3slq-Dg-",
        "outputId": "6e37865e-a0a8-4031-d46c-c89e479bbcf9"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Date='2012-01-03', Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996),\n",
              " Row(Date='2012-01-04', Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475),\n",
              " Row(Date='2012-01-05', Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539),\n",
              " Row(Date='2012-01-06', Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922),\n",
              " Row(Date='2012-01-09', Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av3omIuC8mnt",
        "outputId": "413ea4d0-a27a-45a1-f2b1-3c8f019587fd"
      },
      "source": [
        "for row in df.head(5):\n",
        "  print(row)\n",
        "  print('\\n')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(Date='2012-01-03', Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996)\n",
            "\n",
            "\n",
            "Row(Date='2012-01-04', Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475)\n",
            "\n",
            "\n",
            "Row(Date='2012-01-05', Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539)\n",
            "\n",
            "\n",
            "Row(Date='2012-01-06', Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922)\n",
            "\n",
            "\n",
            "Row(Date='2012-01-09', Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNXxTBgi8mnu"
      },
      "source": [
        "#### Use describe() to learn about the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmiBl1yr-LLo",
        "outputId": "01fa8159-39c3-4101-b3a8-c505af803039"
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|      Date|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|      1258|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean|      null| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|      null|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|2012-01-03|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
            "|    max|2016-12-30|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTQODu0r8mnw"
      },
      "source": [
        "## Bonus Question!\n",
        "#### There are too many decimal places for mean and stddev in the describe() dataframe. Format the numbers to just show up to two decimal places. Pay careful attention to the datatypes that .describe() returns, we didn't cover how to do this exact formatting, but we covered something very similar. [Check this link for a hint](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column.cast)\n",
        "\n",
        "If you get stuck on this, don't worry, just view the solutions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLqcXvkT_rG0",
        "outputId": "36329a0d-dbb2-4d6d-ef31-d41011e70fa7"
      },
      "source": [
        "df.describe().printSchema()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- summary: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Open: string (nullable = true)\n",
            " |-- High: string (nullable = true)\n",
            " |-- Low: string (nullable = true)\n",
            " |-- Close: string (nullable = true)\n",
            " |-- Volume: string (nullable = true)\n",
            " |-- Adj Close: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsVoUC3a_yTH"
      },
      "source": [
        "from pyspark.sql.functions import format_number"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpudZrN9_57c"
      },
      "source": [
        "result = df.describe()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsGkwFGp_8wR",
        "outputId": "4aecbf14-0653-4c97-f8d8-44c868f01423"
      },
      "source": [
        "result.select(result['summary'], \n",
        "              format_number(result['Open'].cast('float'),2).alias('Open'),\n",
        "              format_number(result['High'].cast('float'),2).alias('High'),\n",
        "              format_number(result['Low'].cast('float'),2).alias('Low'),\n",
        "              format_number(result['Close'].cast('float'),2).alias('Close'),\n",
        "              result['Volume'].cast('int').alias('Volume')).show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+--------+--------+--------+--------+\n",
            "|summary|    Open|    High|     Low|   Close|  Volume|\n",
            "+-------+--------+--------+--------+--------+--------+\n",
            "|  count|1,258.00|1,258.00|1,258.00|1,258.00|    1258|\n",
            "|   mean|   72.36|   72.84|   71.92|   72.39| 8222093|\n",
            "| stddev|    6.77|    6.77|    6.74|    6.76| 4519780|\n",
            "|    min|   56.39|   57.06|   56.30|   56.42| 2094900|\n",
            "|    max|   90.80|   90.97|   89.25|   90.47|80898100|\n",
            "+-------+--------+--------+--------+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7ZZ1hpz8mnz"
      },
      "source": [
        "#### Create a new dataframe with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roPS3eNpBUhP",
        "outputId": "21de5787-14f2-47c6-f97f-0af1950ef2c8"
      },
      "source": [
        "df2 = df.withColumn('HV Ratio', df['High']/df['Volume'])\n",
        "df2.select('HV Ratio').show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            HV Ratio|\n",
            "+--------------------+\n",
            "|4.819714653321546E-6|\n",
            "|6.290848613094555E-6|\n",
            "|4.669412994783916E-6|\n",
            "|7.367338463826307E-6|\n",
            "|8.915604778943901E-6|\n",
            "|8.644477436914568E-6|\n",
            "|9.351828421515645E-6|\n",
            "| 8.29141562102703E-6|\n",
            "|7.712212102001476E-6|\n",
            "|7.071764823529412E-6|\n",
            "|1.015495466386981E-5|\n",
            "|6.576354146362592...|\n",
            "| 5.90145296180676E-6|\n",
            "|8.547679455011844E-6|\n",
            "|8.420709512685392E-6|\n",
            "|1.041448341728929...|\n",
            "|8.316075414862431E-6|\n",
            "|9.721183814992126E-6|\n",
            "|8.029436027707578E-6|\n",
            "|6.307432259386365E-6|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0VBn3438mn2"
      },
      "source": [
        "#### What day had the Peak High in Price?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nNdRsQhoBrLH",
        "outputId": "8320fdc0-bc66-4c3f-db4e-ccf50056e85b"
      },
      "source": [
        "df.orderBy(df['High'].desc()).head(1)[0][0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2015-01-13'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu92bDBu8mn3"
      },
      "source": [
        "#### What is the mean of the Close column?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXH703ds8mn5",
        "outputId": "39ca82dc-eb1d-43b4-ac03-721ae34825af"
      },
      "source": [
        "df.agg({'Close':'avg'}).show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|       avg(Close)|\n",
            "+-----------------+\n",
            "|72.38844998012726|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXOY8XSxC5ko",
        "outputId": "3966aba0-c598-440c-f020-d2cd07cc461e"
      },
      "source": [
        "### second way\n",
        "from pyspark.sql.functions import mean\n",
        "df.select(mean('Close')).show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|       avg(Close)|\n",
            "+-----------------+\n",
            "|72.38844998012726|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE9upa5J8mn6"
      },
      "source": [
        "#### What is the max and min of the Volume column?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgwNT5lfC1n7",
        "outputId": "bc78cd3b-7adb-4793-dc2d-ed4099cae3b8"
      },
      "source": [
        "from pyspark.sql.functions import max,min\n",
        "df.select(min('Volume'), max('Volume')).show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|min(Volume)|max(Volume)|\n",
            "+-----------+-----------+\n",
            "|    2094900|   80898100|\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzZBtAAx8mn8"
      },
      "source": [
        "#### How many days was the Close lower than 60 dollars?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsn4VDLNDyHA",
        "outputId": "d3199845-5519-43ef-b2a5-4a84e3f8017b"
      },
      "source": [
        "df.filter('Close < 60').count()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxqAzhMq8mn8",
        "outputId": "1fd722ff-5fd1-4af4-dccf-fc8aafc478c6"
      },
      "source": [
        "df.filter(df['Close']<60).count()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PywWPQGGEC9E"
      },
      "source": [
        "from pyspark.sql.functions import count"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypHzuxjuEG5V"
      },
      "source": [
        "result = df.filter(df['Close']<60)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4rOH1XkEOMt",
        "outputId": "05461c1e-8cf6-41a9-bd5c-82f35bc01f8f"
      },
      "source": [
        "result.select(count('Close')).show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|count(Close)|\n",
            "+------------+\n",
            "|          81|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_IL2Br68mn9"
      },
      "source": [
        "#### What percentage of the time was the High greater than 80 dollars ?\n",
        "#### In other words, (Number of Days High>80)/(Total Days in the dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otyb8NzPEXhb",
        "outputId": "7d87b9fb-d60b-4e05-bf36-57287ce0aa3d"
      },
      "source": [
        "(df.filter(df['High']>80).count() / df.count()) * 100"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.141494435612083"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GftU9wWw8mn-"
      },
      "source": [
        "#### What is the Pearson correlation between High and Volume?\n",
        "#### [Hint](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameStatFunctions.corr)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKLP2iNsF1Me",
        "outputId": "5a39ec8a-6815-475e-ff2e-b256258b36c6"
      },
      "source": [
        "from pyspark.sql.functions import corr\n",
        "df.select(corr('High', 'Volume')).show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "| corr(High, Volume)|\n",
            "+-------------------+\n",
            "|-0.3384326061737161|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJQDXExw8mn-"
      },
      "source": [
        "#### What is the max High per year?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RVc2AbTGHke"
      },
      "source": [
        "from  pyspark.sql.functions import year\n",
        "yeardf = df.withColumn('Year', year(df['Date']))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE_gA_dfGXjP"
      },
      "source": [
        "max_df = yeardf.groupBy('Year').max()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqHnE93IGdxE",
        "outputId": "ed466ea2-8b99-41d6-c2b1-ca17bc59ecf3"
      },
      "source": [
        "max_df.select('Year', 'max(High)').show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|Year|max(High)|\n",
            "+----+---------+\n",
            "|2015|90.970001|\n",
            "|2013|81.370003|\n",
            "|2014|88.089996|\n",
            "|2012|77.599998|\n",
            "|2016|75.190002|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I2XGmh68mn_"
      },
      "source": [
        "#### What is the average Close for each Calendar Month?\n",
        "#### In other words, across all the years, what is the average Close price for Jan,Feb, Mar, etc... Your result will have a value for each of these months. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHnKhYM1G1Sg"
      },
      "source": [
        "from pyspark.sql.functions import month"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaP_q9NDG8Kz"
      },
      "source": [
        "monthdf = df.withColumn('Month', month(df['Date']))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSWYrP9OG8D4"
      },
      "source": [
        "avg_month = monthdf.groupBy('Month').avg()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4z1r6miHODo",
        "outputId": "d214329e-9a12-445c-cce3-06aa11e7489c"
      },
      "source": [
        "avg_month.select('Month', 'avg(Close)').show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|Month|       avg(Close)|\n",
            "+-----+-----------------+\n",
            "|   12|72.84792478301885|\n",
            "|    1|71.44801958415842|\n",
            "|    6| 72.4953774245283|\n",
            "|    3|71.77794377570092|\n",
            "|    5|72.30971688679247|\n",
            "|    9|72.18411785294116|\n",
            "|    4|72.97361900952382|\n",
            "|    8|73.02981855454546|\n",
            "|    7|74.43971943925233|\n",
            "|   10|71.57854545454543|\n",
            "|   11| 72.1110893069307|\n",
            "|    2|  71.306804443299|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia_67MLtH4m-"
      },
      "source": [
        "### second way\n",
        "monthdf2 = df.withColumn('Month', month('Date'))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cbKv623H4jU"
      },
      "source": [
        "monthavgs = monthdf2.select(['Month', 'Close']).groupBy('Month').mean()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJxPXmw0H4gt",
        "outputId": "7d5b2eb3-4f94-4f49-dc28-715d9e21cd86"
      },
      "source": [
        "monthavgs.select('Month','avg(Close)').orderBy('Month').show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|Month|       avg(Close)|\n",
            "+-----+-----------------+\n",
            "|    1|71.44801958415842|\n",
            "|    2|  71.306804443299|\n",
            "|    3|71.77794377570092|\n",
            "|    4|72.97361900952382|\n",
            "|    5|72.30971688679247|\n",
            "|    6| 72.4953774245283|\n",
            "|    7|74.43971943925233|\n",
            "|    8|73.02981855454546|\n",
            "|    9|72.18411785294116|\n",
            "|   10|71.57854545454543|\n",
            "|   11| 72.1110893069307|\n",
            "|   12|72.84792478301885|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiQSX-KH8moA"
      },
      "source": [
        "# Great Job!"
      ]
    }
  ]
}